\chapter{基于深度学习的元基因组归类算法}
\rhead{基于深度学习的元基因组归类算法}

基于深度学习的归类算法也同样包含三步：1) 用$k$-mer频率向量来表示序列 ~2) 用自动编码机(或RBM)对$k$-mer特征进行特征学习 ~3) 采用SKWIC
算法对向量化的序列进行归类。图~\ref{fig:10}中显示了工作流程。
\begin{figure}[h!]
\centering
    \includegraphics[width=17cm]{./example/AEModulePipeline.eps}
    %\caption{\csentence{The pipeline of the \emph{TM-MCluster} method.}
    \caption{基于深度学习的元基因组归类算法的工作流程}
            \label{fig:10}
\end{figure}

\section{基于自动编码机的特征学习}
自动编码机有很多参数需要进行选择，我们经过参数调节，最终决定采用3个自动编码机，每个编码机采用隐含层的特征个数分别为1024,1024 和512。
批处理的样本个数为1000，最大迭代次数为500.最终学习的特征个数为512个。我们采用了LBFGS算法\cite{ngiam2011optimization}来求解自动编码机中的参数。

\section{基于RBM的特征学习}
RBM采用了两层的神经单元组成， 经过参数调节，我们采用1000个特征作为最后学习的特征。我们采用Gibbs 采样的方法求解RBM中的参数。

\section{模拟数据集}
由于深度学习对于较大的数据集效果较好，因此我们采用500k, 1000k和3000k的序列进行特征学习。具体的，500k的数据集S5、S6、S7、S8、S9 和S10，1000k的数据集A、B，3000k的数据集为C、D、E、F和G。具体的数据说明在上一章数据集已经进行了说明。

评价标准依然采用Precision、Sensitivity以及F1-score作为归类算法的评价标准。

\section{实验结果}

\subsection{$k$-mer的影响}
我们分析$k$-mer对于实验结果的影响，

\begin{figure}[h!]
\centering
    \includegraphics[width=17cm]{./example/KmerAnalysis.eps}
    %\caption{\csentence{The pipeline of the \emph{TM-MCluster} method.}
    \caption{$k$-mer对于自动编码机特征学习的影响}
            \label{fig:10}
\end{figure}

当$k$增大时，特征会变得稀疏，然而深度学习是可以处理这种稀疏性的。我们首先调节好自动编码机的层数，然后观察$k$=4和$k$=5的条件下，5个数据集的实验结果对比。


\iffalse

\begin{table}[htbp]
\centering
    \caption{$k$=4和5时，自动编码机在500k序列的模拟数据上的归类结果。加粗数值表示某个数据集上的最好结果。}
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{3}{|c|}{\textbf{$k$=4}}&\multicolumn{3}{|c|}{\textbf{$k$=5}}\\
    \cline{2-7}
    &Pr&Se&F1&Pr&Se&F1\\
    \hline
    S6	& .9889&	.9889&	.9889&	\textbf{.9913}&	\textbf{.9913}&	\textbf{.9913}\\
    \hline
    S7	& 	\textbf{.9022}&	\textbf{.9022}&	\textbf{.9022}&	.7325&	.7646&	.7482\\
    \hline
    S8	& 	.8450&.8450	&.8450&	\textbf{.8632}&	\textbf{.8632}&	\textbf{.8632}\\
    \hline
    S9	& 	\textbf{.8292}&	\textbf{.8292}&	\textbf{.8292}&	.8244&	.7219&	.7698	\\
    \hline
    S10	& 	.7216&	.715&	.7183&	\textbf{.7748}&	\textbf{.7659}&	\textbf{.7703}	\\
    \hline
    \end{tabular}
    \label{tab:5}
\end{table}

通过查看$k$=4和$k$=5时，500k的5个数据集S6-S10在自动编码机上的性能比较，可以看出在S6、S8和S10上$k$=5时F1值更高。
S7和S9上$k$=4时F1值更高。

\fi

\subsection{自动编码机个数及神经网络单元个数的影响}
可以采用多个自动编码机来进行特征的多次提取，这样可以学习到更好的特征。
具体的，采用多层自动编码机对特征进行学习。

\begin{table}[htbp]
\centering
    \caption{自动编码机不同层数的归类效果。}
    \begin{tabular}{|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{神经网络个数及每层单元个数}} & \multicolumn{3}{|c|}{\textbf{AutoEncoder}}\\
    \cline{2-4}
    &Pr&Se&F1\\

  %  \hline
  %  D1&\textbf{.9989}&.9628	&.9805&	.9877&	.9877	&.9877	&.9882	&\textbf{.9882}	&\textbf{.9882}\\
    \hline
    [512]&		.7244&	.7183&	.7214	\\
    \hline
    [1024]&		.4478&	.4092&	.4277\\
    \hline
    [1024 512]&.7258	&.7214	&.7236\\
    \hline
    [1024 1024 512]&.7224	&.7169	&.7196\\
    \hline
    \end{tabular}
    \label{tab:9}
\end{table}

通过实验分析，采用三个自动编码机，层数分别为1024、1024和512时，F1值最高。


\subsection{模拟数据集实验结果}
多层自动编码机可以学习到更好的特征，我们选择3个自动编码机进行特征学习，采用4-mer, 输入特征为256， 输出的特征数为512，也即采用了3个自动编码机(SAE) 进行特征学习，层数分别为1024、1024和512个。RBM采用4-mer, 输出特征是1000，执行300轮迭代，稀疏项系数为0.01， 惩罚项系数是0.002。
然后同样采用SKWIC算法对学习到的特征进行归类，实验结果如表\ref{tab:9}：
\iffalse
                      Precision Sensitivity F1
500k 2class 1-1        0.988922 0.988922 0.988922
500k 3class 1-1-1     0.902198 0.902198 0.902198
500k 3class 1-3-9     0.84502 0.84502 0.84502
500k 5class           0.829206 0.829206 0.829206
500k 10class          0.721574 0.714996 0.71827

1M 20species          0.404149 0.233673 0.296129
1M 50species           0.21230 0.31289  0.252961

3000k 2class            0.819216 0.819216 0.819216
3000k 3class            0.619232 0.619232 0.619232
3000k 3class-abundance  0.980533 0.980533 0.980533
3000k 5class            0.7784 0.977165 0.86653
3000k 10class           0.302841 0.793249 0.438337
\fi
\begin{table}[htbp]
\centering
    \caption{采用自动编码机和RBM在12个数据集上的归类效果。}
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Dataset}} & \multicolumn{3}{|c|}{\textbf{AutoEncoder}}  & \multicolumn{3}{|c|}{\textbf{RBM}} \\
    \cline{2-7}
    &Pr&Se&F1 &Pr&Se&F1 \\

  %  \hline
  %  D1&\textbf{.9989}&.9628	&.9805&	.9877&	.9877	&.9877	&.9882	&\textbf{.9882}	&\textbf{.9882}\\
    \hline
    S6&		.9889&	.9889&	.9889	&.9913&	.9913&	.9913\\
    \hline
    S7&		.9022&	.9022&	.9022  &.7325&	.7646&	.7482\\
    \hline
    S8&.8450	&.8450	&.8450 &.8632&.8632	&.8632\\
    \hline
    S9		&.8292&	.8292&	.8292 &.8244	&.7219	&.7698\\
    \hline
    S10	&	.7216&	.7150&	.7183 & .7748&	7659&	.7703\\
    \hline
    A		&.4041&	.2337&	.2961 & .3748&	2659&	.3111\\
    \hline
    B		&.2123&	.3129&	.2530 & .2748&	2659&	.2703\\
    \hline
    C	&.8192&	.8192&	.8192 & .8748&	7659&	.8167\\
    \hline
    D	&	.6192&	.6192&	.6192 & .6748&	6659&	.6703\\
    \hline
    E		&	.9805&	.9805&	.9805 & .8748&	7659&	.8167\\
    \hline
    F&	.7784&	.9772&	.8665 & .7948&	7659&	.7801\\
    \hline
    G	&	.3028&	.7932&	.4383 & .3748&	7659&	.5033\\
    \hline
    \end{tabular}
    \label{tab:9}
\end{table}
%通过实验结果可以知道，自动编码机归类效果在12个数据集上都优于RBM。
通过实验结果知道，在有些数据集上，自动编码机的归类效果要优于RBM，这是和数据分布有关系的。

\section{小结}
本章中，我们介绍了目前非常流行的深度学习，对元基因组数据进行归类是非监督学习任务，采用自动编码机进行特征学习，
然后采用SKWIC算法进行归类。实验结果也表明，基于深度学习的方法也取得了不错的归类效果。

