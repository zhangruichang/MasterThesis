\chapter{基于主题模型的宏基因组聚类算法}
\rhead{图上可达性查询的隐私保护算法}

本文提出的方法包含三步：1) 用k-mer频率向量来表示序列 2) 通过LDA模型，将每个k-mer频率向量转化为主题分布向量 3) 和MCluster一样，用SKWIC
算法对向量化的序列进行聚类。图1中显示了TM-MCluster的工作流程，随后将给出每一步的具体细节。




 \section{用k-mer来表示序列}
 一般来说，k-mer表示序列中k个连续字符组成的子序列。元基因组数据来自不同物种的很多序列组成，我们使用k-mer来刻画序列的特征。DNA序列一共有4 种不同的核苷酸，因此一个DNA序列中
 最多有$4_{k}$个k-mer。一个序列对应的k-mer频率作为其中的一个分量。为了减少计算量，k值不宜取得过大。事实上，不同的k-mer在描述DNA序列方面有不同的
 影响，正如文献~\cite{chor2009genomic,zhou2008barcodes}中所说的，在2到7的范围里,k=4是最适合表示DNA序列的，因此我们使用k=4来表示元基因序列。具体的说，我们滑动一个长为4 的窗口来统计一个序列中k-mer的频率，他的互补序列也同样被考虑，因此一个序列的维度是256.

  \section{将序列从k-mer空间转换到主题空间}
元基因组中，序列被当成文档，k-mer被当成关键词，来自同一物种的序列应该比不同物种的序列有更多相似的主题信息，因此，对于目前考虑的
归类问题，主题信息在描述元基因组序列方面可能比k-mer更有效。我们采用隐含狄利克雷分布(LDA)--一个机器学习领域非常流行的主题来处理这个问题。在上一章中，我们也对主题模型进行了介绍。

After training a LDA model, we can get the topic distribution of each read. Fig.~\ref{fig:3} illustrates the application of LDA to metagenomic reads. The left layer represents the DNA reads, the middle layer represents topics, and the right layer represents $k$-mers. We use the topic distribution of each read to represent the read. As the number of topics is usually smaller than the number of $k$-mers, this process is equivalent to dimension reduction. Here, the number of topics is a tunable parameter. In our experimental study, we set it to be 20 and 100 for simulated data and real data, respectively.
\section{用SKWIC算法对向量化的序列进行聚类}
%\subsection*{Clustering the vectorized reads by the SKWIC algorithm}
和MCluster一样~\cite{liao2014new}, 我们采用 SKWIC 算法 对向量化的元基因序列进行聚类. SKWIC是在经典的$K$-means算法基础上增加了自动加权机制的聚类算法~\cite{frigui2004simultaneous}.  %K-means or K-median method was proposed in existing unsupervised methods, and features are equally treated in their method. However, the relationships between clusters and their feature sets need to be discovered in the binning process. In order to tackle this issue, Frigui et al proposed SKWIC algorithm which is a variant of classical K-means method. Roughly speaking, k-mer preference was exploited to improve the performance of clustering in this method. Furthermore, k-mer preference can also boost the clustering performance of bioinformatics problems, which was validated in miRNA sequences clustering~\cite{yi2012effective} and metagenomic sequences binning~\cite{liao2014new}.
%As a variant of K-means,
它试图最小化下面的目标函数:
\begin{equation}\label{eq1}
J(K,V;\chi)=
\sum_{i=1}^{K}
\sum_{x_{j}\in \chi_{i}}
%$\sum_{$x_{j}$ $\in$ $\chi$}$
\sum_{k=1}^{n}
v_{ik}D^{k}_{wc_{ij}}
+\sum_{i=1}^{K}\delta_{i}
\sum_{k=1}^{n}v_{ik}^{2}
%J(C,V;)
%\eqno{(1)}
\end{equation}
subject to
\begin{equation}\label{eq2}
v_{ik}
\in [0,1]\quad
\forall
i,k \quad and \quad \sum_{k=1}^{n}v_{ik}=1,\quad \forall i
\end{equation}
\emph{K} 是类的个数, \emph{n} 是特征的个数, 这里是主题的个数. $X_{i}$ 是第\emph{i}个类的序列个数, $v_{ik}$ 是第\emph{i}个类在第\emph{k} 个特征上的权值, $D^{k}_{wc_{ij}}$ 是第\emph{j}条序列和第\emph{i}个类中心在第\emph{k}维特征上的距离。
在这个目标函数中，我们应该选择一种距离度量方式。根据\cite{liao2014new}中的结论，和欧式距离以及余弦距离相比，曼哈顿距离在对生物序列进行聚类时效果最佳，因此此处我们也采用曼哈顿距离进行距离度量。

与传统的$K$-means 算法不同，目标函数(\ref{eq1})额外考虑了每一维特征对于每一个类的权重$v_{ik}$.
$\delta_{i}$ 来权衡$v_{ik}$ 的相对重要性。为了解决这个优化问题，我们采用拉格朗日乘子法，
\begin{equation}\label{eq3}
v_{ik}=\frac{1}{n}+\frac{1}{2\delta_{i}}\sum_{x_{j}\in\chi_{i}}
[\frac{\sum_{l=1}^{n}D^{l}_{wc_{ij}}}{n}-D^{k}_{wc_{ij}}].
\end{equation}
%The parameter $\delta_{i}$ in the above equations is important because it is used to weight the relative importance of the second component in Eq.~\eqref{eq1}. If $\delta_{i}$ is too small, then the contribution of the second part in Eq.~\eqref{eq1} will be negligible, and one dimension in cluster $i$ will have a relative high weight {\color{red}compared to} other dimensions, which would have a quite small weight or even a zero weight. On the other hand, if $\delta_{i}$ is chosen too large, then almost all dimensions in cluster $i$ will be equally weighted by $\frac{1}{n}$ approximately.

$\delta_{i}$ 计算公式如下：

\begin{equation}\label{eq4}
\delta^{(t)}_{i}=K_{\delta}\frac{\sum_{x_{j}\in\chi^{(t-1)}_{i}}\sum_{k=1}^{n}v^{(t-1)}_{ik}(D^{k}_{wc_{ij}})^{(t-1)}}
{\sum_{k=1}^{n}(v^{(t-1)}_{ik})^2}.
\end{equation}

SKWIC的聚类过程就是重复下面的步骤直到类中心不变或者变化范围足够小：
\begin{enumerate}
\item 设定聚类个数为 \emph{K}  (序列所属的物种数);
\item 随机选择 \emph{K} 个类的类中心, 并将权值矩阵设定为$v_{ik}$=$\frac{1}{n}$;
\item 利用公式~\eqref{eq3}更新权值矩阵$v_{ik}$;
\item 将序列归到距离它最近的类;
\item 更新每个类的类中心;
\item 利用公式~\eqref{eq4}更新$\delta_{i}$
\end{enumerate}







